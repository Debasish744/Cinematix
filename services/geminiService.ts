
import { GoogleGenAI, Type } from "@google/genai";
import { SceneBreakdown, ToolPreset } from "../types";

const API_KEY = process.env.API_KEY || '';

export class GeminiService {
  private ai: GoogleGenAI;

  constructor() {
    this.ai = new GoogleGenAI({ apiKey: API_KEY });
  }

  async generateVideoPrompt(params: {
    concept: string;
    duration: number;
    style: string;
    aspectRatio: string;
    tool: ToolPreset;
  }): Promise<any> {
    const { concept, duration, style, aspectRatio, tool } = params;

    let toolGuidance = "";
    if (tool === ToolPreset.SORA) {
      toolGuidance = "Use the 4C Model: Camera + Character + Context + Cinematic. Ensure it handles complex physics and narrative. Output should be a cohesive paragraph.";
    } else if (tool === ToolPreset.RUNWAY) {
      toolGuidance = "Format the prompt exactly as: 'camera: [motion] | style: [style] | subject: [subject]'. Focus on camera motion and high-fidelity physics.";
    } else if (tool === ToolPreset.PIKA) {
      toolGuidance = "Front-load the action. Structure: '[Subject] [Dynamic Action], [Visual Effects], [Background], [Style]'. Ensure precise timing breakdown.";
    }

    const response = await this.ai.models.generateContent({
      model: "gemini-3-pro-preview",
      contents: `You are a world-class AI Video Director. Generate a high-end video prompt for ${tool} based on: "${concept}".
      Duration: ${duration}s. Style: ${style}. Aspect Ratio: ${aspectRatio}.
      
      ${toolGuidance}
      
      You MUST provide:
      1. masterPrompt: The optimized generation string.
      2. breakdown: JSON array of scenes with duration, type, camera, lighting, description.
      3. analysis: Break down the prompt into 4C components (camera, character, context, cinematic) as separate strings.`,
      config: {
        thinkingConfig: { thinkingBudget: 4000 },
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            masterPrompt: { type: Type.STRING },
            breakdown: {
              type: Type.ARRAY,
              items: {
                type: Type.OBJECT,
                properties: {
                  duration: { type: Type.NUMBER },
                  type: { type: Type.STRING },
                  camera: { type: Type.STRING },
                  lighting: { type: Type.STRING },
                  description: { type: Type.STRING }
                },
                required: ["duration", "type", "camera", "lighting", "description"]
              }
            },
            analysis: {
              type: Type.OBJECT,
              properties: {
                camera: { type: Type.STRING },
                character: { type: Type.STRING },
                context: { type: Type.STRING },
                cinematic: { type: Type.STRING }
              }
            }
          },
          required: ["masterPrompt", "breakdown", "analysis"]
        }
      }
    });

    try {
      return JSON.parse(response.text);
    } catch (e) {
      console.error("Failed to parse Gemini response", e);
      throw new Error("Invalid response format from AI");
    }
  }

  async generateImage(prompt: string, aspectRatio: string = "16:9"): Promise<string> {
    const response = await this.ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: {
        parts: [{ text: `High-quality cinematic visual reference/storyboard frame: ${prompt}. Cinematic lighting, 8k, detailed textures.` }],
      },
      config: {
        imageConfig: {
          aspectRatio: aspectRatio as any,
        },
      },
    });

    for (const part of response.candidates?.[0]?.content?.parts || []) {
      if (part.inlineData) {
        return `data:image/png;base64,${part.inlineData.data}`;
      }
    }
    throw new Error("Image generation failed");
  }

  async editImage(base64Image: string, instruction: string): Promise<string> {
    const response = await this.ai.models.generateContent({
      model: "gemini-2.5-flash-image",
      contents: {
        parts: [
          {
            inlineData: {
              data: base64Image.split(',')[1],
              mimeType: 'image/png'
            }
          },
          { text: instruction }
        ]
      }
    });

    for (const part of response.candidates?.[0]?.content?.parts || []) {
      if (part.inlineData) {
        return `data:image/png;base64,${part.inlineData.data}`;
      }
    }
    throw new Error("No image was generated by the model.");
  }
}

export const gemini = new GeminiService();
